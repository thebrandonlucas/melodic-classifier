{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date: 4/4/2019\n",
    "# Author: Brandon Lucas\n",
    "# Research Professor: Dr. Ian McDonough\n",
    "\n",
    "# what modules do we need?\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from organize_melodic_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_dir = \"C:/Users/thebr/Desktop/Programming/melodic-classifier/testing_data\"\n",
    "data_dir = \"C:/Users/thebr/Desktop/Programming/melodic-classifier/testing_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.chdir(orig_dir)\n",
    "except:\n",
    "    print('Could not change to that directory')\n",
    "    sys.exit(0)\n",
    "\n",
    "artifact_images = []\n",
    "non_artifact_images = []\n",
    "count = 0\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    for directory in dirs:\n",
    "        # make this an option later\n",
    "        if \"Preclin\" in directory:\n",
    "            os.chdir(directory)\n",
    "            # the files that indicate which id's are artifacts\n",
    "            artifact_numbers_file = open(\"fix_s8.txt\")\n",
    "            line = artifact_numbers_file.readline()\n",
    "            artifact_numbers_file.close()\n",
    "            artifact_numbers = line.strip().split(\",\")\n",
    "            # every var after \"t\" is substrings to exclude\n",
    "#             thresh_files = getFiles(root + '/' + directory, \"t\", \"EV\", \"index\", \"IC\", \"._\", \"f\", \".html\", \"DS\", \"txt\")\n",
    "            thresh_files = getFiles(root + '/' + directory, \"thresh\", \"._\")\n",
    "            # loop through the thresh files\n",
    "            for file_path in thresh_files:\n",
    "                filename = file_path.split(\"/\")[-1]\n",
    "#                 id = filename[filename.rindex('t')+1:].split(\".\")[0]\n",
    "                id = filename.split(\"_\")[1]\n",
    "                if id in artifact_numbers:\n",
    "                    artifact_images.append(file_path)\n",
    "                else:\n",
    "                    non_artifact_images.append(file_path)\n",
    "        os.chdir(root)\n",
    "\n",
    "# image = Image.open(artifact_images[0])\n",
    "# image = image.resize((238, 1000))\n",
    "# image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "for artifact_image in artifact_images:\n",
    "    image = mpimg.imread(artifact_image)\n",
    "    image_from_array = Image.fromarray(image, 'RGB')\n",
    "#     image = Image.open(artifact_image)\n",
    "    size_image = image_from_array.resize((238, 1000))\n",
    "#     size_image = image_from_array\n",
    "#     image = image.resize((992, 4167))\n",
    "#     data.append(np.array(image))\n",
    "    data.append(np.array(size_image))\n",
    "    labels.append(1)\n",
    "    \n",
    "for non_artifact_image in non_artifact_images:\n",
    "#     image = mpimg.imread(non_artifact_image)\n",
    "#     image_from_array = Image.fromarray(image, 'RGB')\n",
    "#     size_image = image_from_array.resize((992, 4167))\n",
    "#     image = Image.open(artifact_image)\n",
    "#     image = image.resize((992, 4167))\n",
    "#     data.append(np.array(image))\n",
    "    image = mpimg.imread(artifact_image)\n",
    "    image_from_array = Image.fromarray(image, 'RGB')\n",
    "#     image = Image.open(artifact_image)\n",
    "    size_image = image_from_array.resize((238, 1000))\n",
    "#     image_from_array = Image.fromarray(image, 'RGB').crop(0, height/2, 0, 0)\n",
    "#     image = image.resize((992, 4167))\n",
    "#     data.append(np.array(image))\n",
    "    data.append(np.array(size_image))\n",
    "#     data.append(np.array(size_image))\n",
    "    labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri = np.array(data)\n",
    "labels = np.array(labels)\n",
    "s = np.arange(mri.shape[0])\n",
    "np.random.shuffle(s)\n",
    "mri = mri[s]\n",
    "labels = labels[s]\n",
    "\n",
    "# (X_train, X_test) = df[(int)(0.1*len(df)):],df[:(int)(0.1*len(df))]\n",
    "# (y_train, y_test) = labels[(int)(0.1*len(labels)):],labels[:(int)(0.1*len(labels))]\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(558, 1000, 238, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, X_test) = mri[(int)(0.1*len(mri)):], mri[:(int)(0.1*len(mri))]\n",
    "# X_train = X_train.astype('float32') / 255 # normalize data by 255 for images\n",
    "# X_test = X_test.astype('float32') / 255\n",
    "train_len = len(X_train)\n",
    "test_len = len(X_test)\n",
    "\n",
    "(y_train, y_test) = labels[(int)(0.1*len(labels)):],labels[:(int)(0.1*len(labels))]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.applications.inception_v3 import InceptionV3\n",
    "# from keras.layers import Input\n",
    "\n",
    "# input_tensor = Input(shape=(238, 1000, 3))  # this assumes K.image_data_format() == 'channels_last'\n",
    "# model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_47 (Conv2D)           (None, 1000, 238, 16)     208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 500, 119, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 500, 119, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 500, 119, 16)      1040      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 250, 59, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 250, 59, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 250, 59, 64)       4160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 125, 29, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 125, 29, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 125, 29, 128)      32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 62, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 62, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 111104)            0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 500)               55552500  \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 2)                 502       \n",
      "=================================================================\n",
      "Total params: 55,716,556\n",
      "Trainable params: 55,716,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(1000, 238, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(1000, 238, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(1000, 238, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(250, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2,activation=\"softmax\"))#2 represent output layer neurons\n",
    "model.summary()\n",
    "# img_height = 1000\n",
    "# img_width = 238\n",
    "# img_channels = 3\n",
    "\n",
    "# #\n",
    "# # network params\n",
    "# #\n",
    "\n",
    "# cardinality = 1\n",
    "\n",
    "\n",
    "# def residual_network(x):\n",
    "#     \"\"\"\n",
    "#     ResNeXt by default. For ResNet set `cardinality` = 1 above.\n",
    "    \n",
    "#     \"\"\"\n",
    "#     def add_common_layers(y):\n",
    "#         y = layers.BatchNormalization()(y)\n",
    "#         y = layers.LeakyReLU()(y)\n",
    "\n",
    "#         return y\n",
    "\n",
    "#     def grouped_convolution(y, nb_channels, _strides):\n",
    "#         # when `cardinality` == 1 this is just a standard convolution\n",
    "#         if cardinality == 1:\n",
    "#             return layers.Conv2D(nb_channels, kernel_size=(3, 3), strides=_strides, padding='same')(y)\n",
    "        \n",
    "#         assert not nb_channels % cardinality\n",
    "#         _d = nb_channels // cardinality\n",
    "\n",
    "#         # in a grouped convolution layer, input and output channels are divided into `cardinality` groups,\n",
    "#         # and convolutions are separately performed within each group\n",
    "#         groups = []\n",
    "#         for j in range(cardinality):\n",
    "#             group = layers.Lambda(lambda z: z[:, :, :, j * _d:j * _d + _d])(y)\n",
    "#             groups.append(layers.Conv2D(_d, kernel_size=(3, 3), strides=_strides, padding='same')(group))\n",
    "            \n",
    "#         # the grouped convolutional layer concatenates them as the outputs of the layer\n",
    "#         y = layers.concatenate(groups)\n",
    "\n",
    "#         return y\n",
    "\n",
    "#     def residual_block(y, nb_channels_in, nb_channels_out, _strides=(1, 1), _project_shortcut=False):\n",
    "#         \"\"\"\n",
    "#         Our network consists of a stack of residual blocks. These blocks have the same topology,\n",
    "#         and are subject to two simple rules:\n",
    "#         - If producing spatial maps of the same size, the blocks share the same hyper-parameters (width and filter sizes).\n",
    "#         - Each time the spatial map is down-sampled by a factor of 2, the width of the blocks is multiplied by a factor of 2.\n",
    "#         \"\"\"\n",
    "#         shortcut = y\n",
    "\n",
    "#         # we modify the residual building block as a bottleneck design to make the network more economical\n",
    "#         y = layers.Conv2D(nb_channels_in, kernel_size=(1, 1), strides=(1, 1), padding='same')(y)\n",
    "#         y = add_common_layers(y)\n",
    "\n",
    "#         # ResNeXt (identical to ResNet when `cardinality` == 1)\n",
    "#         y = grouped_convolution(y, nb_channels_in, _strides=_strides)\n",
    "#         y = add_common_layers(y)\n",
    "\n",
    "#         y = layers.Conv2D(nb_channels_out, kernel_size=(1, 1), strides=(1, 1), padding='same')(y)\n",
    "#         # batch normalization is employed after aggregating the transformations and before adding to the shortcut\n",
    "#         y = layers.BatchNormalization()(y)\n",
    "\n",
    "#         # identity shortcuts used directly when the input and output are of the same dimensions\n",
    "#         if _project_shortcut or _strides != (1, 1):\n",
    "#             # when the dimensions increase projection shortcut is used to match dimensions (done by 1×1 convolutions)\n",
    "#             # when the shortcuts go across feature maps of two sizes, they are performed with a stride of 2\n",
    "#             shortcut = layers.Conv2D(nb_channels_out, kernel_size=(1, 1), strides=_strides, padding='same')(shortcut)\n",
    "#             shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "#         y = layers.add([shortcut, y])\n",
    "\n",
    "#         # relu is performed right after each batch normalization,\n",
    "#         # expect for the output of the block where relu is performed after the adding to the shortcut\n",
    "#         y = layers.LeakyReLU()(y)\n",
    "\n",
    "#         return y\n",
    "\n",
    "#     # conv1\n",
    "#     x = layers.Conv2D(64, kernel_size=(7, 7), strides=(2, 2), padding='same')(x)\n",
    "#     x = add_common_layers(x)\n",
    "\n",
    "#     # conv2\n",
    "#     x = layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "#     for i in range(3):\n",
    "#         project_shortcut = True if i == 0 else False\n",
    "#         x = residual_block(x, 128, 256, _project_shortcut=project_shortcut)\n",
    "\n",
    "#     # conv3\n",
    "#     for i in range(4):\n",
    "#         # down-sampling is performed by conv3_1, conv4_1, and conv5_1 with a stride of 2\n",
    "#         strides = (2, 2) if i == 0 else (1, 1)\n",
    "#         x = residual_block(x, 256, 512, _strides=strides)\n",
    "\n",
    "#     # conv4\n",
    "#     for i in range(6):\n",
    "#         strides = (2, 2) if i == 0 else (1, 1)\n",
    "#         x = residual_block(x, 512, 1024, _strides=strides)\n",
    "\n",
    "#     # conv5\n",
    "#     for i in range(3):\n",
    "#         strides = (2, 2) if i == 0 else (1, 1)\n",
    "#         x = residual_block(x, 1024, 2048, _strides=strides)\n",
    "\n",
    "#     x = layers.GlobalAveragePooling2D()(x)\n",
    "#     x = layers.Dense(1)(x)\n",
    "\n",
    "#     return x\n",
    "\n",
    "\n",
    "# image_tensor = layers.Input(shape=(img_height, img_width, img_channels))\n",
    "# network_output = residual_network(image_tensor)\n",
    "  \n",
    "# model = models.Model(inputs=[image_tensor], outputs=[network_output])\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"loss\", patience=10, verbose=0, mode=\"min\")\n",
    "mcp_save = ModelCheckpoint('model_weights.hdf5', save_best_only=True, monitor=\"loss\", mode=\"min\")\n",
    "# reduce_lr_loss = ReduceLROnPlateu(monitor=\"val_loss\", factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "558/558 [==============================] - 106s 191ms/step - loss: 6.1506 - acc: 0.6183\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thebr\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "C:\\Users\\thebr\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:434: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558/558 [==============================] - 102s 183ms/step - loss: 6.1237 - acc: 0.6201\n",
      "Epoch 3/50\n",
      "558/558 [==============================] - 102s 184ms/step - loss: 6.1237 - acc: 0.6201\n",
      "Epoch 4/50\n",
      "558/558 [==============================] - 103s 184ms/step - loss: 6.1237 - acc: 0.6201\n",
      "Epoch 5/50\n",
      "558/558 [==============================] - 103s 184ms/step - loss: 6.1237 - acc: 0.6201\n",
      "Epoch 6/50\n",
      "558/558 [==============================] - 103s 184ms/step - loss: 6.1237 - acc: 0.6201\n",
      "Epoch 7/50\n",
      "558/558 [==============================] - 103s 185ms/step - loss: 6.1237 - acc: 0.6201\n",
      "Epoch 8/50\n",
      "558/558 [==============================] - 102s 183ms/step - loss: 6.1237 - acc: 0.6201\n",
      "Epoch 9/50\n",
      "558/558 [==============================] - 101s 182ms/step - loss: 6.1237 - acc: 0.6201\n",
      "Epoch 10/50\n",
      "558/558 [==============================] - 103s 184ms/step - loss: 6.1237 - acc: 0.6201\n",
      "Epoch 11/50\n",
      "558/558 [==============================] - 103s 185ms/step - loss: 6.1237 - acc: 0.6201\n",
      "Epoch 12/50\n",
      "558/558 [==============================] - 104s 186ms/step - loss: 6.1237 - acc: 0.6201\n",
      "Epoch 13/50\n",
      "558/558 [==============================] - 102s 183ms/step - loss: 6.1237 - acc: 0.6201\n",
      "Epoch 14/50\n",
      "558/558 [==============================] - 103s 185ms/step - loss: 6.1237 - acc: 0.6201\n",
      "Epoch 15/50\n",
      "558/558 [==============================] - 103s 184ms/step - loss: 6.1237 - acc: 0.6201\n",
      "Epoch 16/50\n",
      "558/558 [==============================] - 103s 184ms/step - loss: 6.1237 - acc: 0.6201\n",
      "Epoch 17/50\n",
      "558/558 [==============================] - 102s 183ms/step - loss: 6.1237 - acc: 0.6201\n",
      "Epoch 18/50\n",
      "150/558 [=======>......................] - ETA: 1:16 - loss: 6.2323 - acc: 0.6133"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-98f0445fce03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmcp_save\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train, batch_size=15, epochs=50, callbacks=[early_stopping, mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Received a label value of 1 which is outside the valid range of [0, 1).  Label values: 1 1 0 1 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1\n\t [[{{node loss_6/dense_12_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-aa6359b2936a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1111\u001b[0m                                          \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m                                          \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1113\u001b[1;33m                                          steps=steps)\n\u001b[0m\u001b[0;32m   1114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m     def predict(self, x,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Received a label value of 1 which is outside the valid range of [0, 1).  Label values: 1 1 0 1 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1\n\t [[{{node loss_6/dense_12_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]"
     ]
    }
   ],
   "source": [
    "X_loss, accuracy = model.evaluate(X_test,y_test)\n",
    "\n",
    "print(accuracy)\n",
    "print(X_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
