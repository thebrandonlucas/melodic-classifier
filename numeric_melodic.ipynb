{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mac2researchlab/Desktop/brandon_melodic/melodic-classifier\n"
     ]
    }
   ],
   "source": [
    "scriptDir = \"/Users/mac2researchlab/Desktop/brandon_melodic/melodic-classifier\"\n",
    "origDir = \"/Volumes/NexStar3/Preclinical_fMRI_Converted\"\n",
    "print(scriptDir)\n",
    "def getFiles(path, substring, *args):\n",
    "    array = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "            for file in files:\n",
    "                stop = False\n",
    "                if substring in file:\n",
    "                    for arg in args: \n",
    "                        if arg in file: \n",
    "                            stop = True\n",
    "                    if stop is True: \n",
    "                        continue\n",
    "                    filepath = root + '/' + file\n",
    "                    array.append(filepath)\n",
    "                    # print(filepath)\n",
    "    return array;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(origDir)\n",
    "\n",
    "f_artifact = []\n",
    "t_artifact = []\n",
    "f_non_artifact = []\n",
    "t_non_artifact = []\n",
    "count = 0\n",
    "for root, dirs, files in os.walk(origDir):\n",
    "    for directory in dirs:\n",
    "        # make this an option later\n",
    "        if \"Preclin\" in directory:\n",
    "            mriDirs = []\n",
    "            for d in os.listdir(directory): \n",
    "                if \"Encoding1_AP_MB4_2_5mmISO_2\" in d: \n",
    "                    mriDirs.append(d)\n",
    "            os.chdir(directory)\n",
    "            for d in mriDirs: \n",
    "                # the files that indicate which id's are artifacts\n",
    "                if \"fix_s8.txt\" in os.listdir(d):\n",
    "                    artifact_numbers_file = open(d + \"/fix_s8.txt\")\n",
    "                else: \n",
    "                    continue\n",
    "                for d2 in os.listdir(d): \n",
    "                    if \"melodic_s8\" in d2: \n",
    "                        melodic_folder = d2\n",
    "                os.chdir(d)\n",
    "                # switch into melodic dir \n",
    "                line = artifact_numbers_file.readline()\n",
    "                artifact_numbers_file.close()\n",
    "                artifact_numbers = line.strip().split(\",\")\n",
    "                # every var after \"t\" is substrings to exclude\n",
    "                directory = root + '/' + directory + '/' + d + '/' + melodic_folder + '/report'\n",
    "                f_files = getFiles(directory, \"f\", \"EV\", \"index\", \"IC\", \"._\", \".html\", \"DS\", \"png\", \"fix\")\n",
    "                t_files = getFiles(directory, \"t\", \"EV\", \"index\", \"IC\", \"._\", \"f\", \".html\", \"DS\", \"png\", \"fix\")\n",
    "                for file_path in f_files:\n",
    "                    filename = file_path.split(\"/\")[-1]\n",
    "                    file_id = filename.split(\"f\")[1]\n",
    "                    file_id = file_id.split(\".\")[0]\n",
    "                    if file_id in artifact_numbers:\n",
    "                        f_artifact.append(file_path)\n",
    "                    else:\n",
    "                        f_non_artifact.append(file_path)\n",
    "                for file_path in t_files:\n",
    "                    filename = file_path.split(\"/\")[-1]\n",
    "                    file_id = filename.split(\"t\")[1]\n",
    "                    file_id = file_id.split(\".\")[0]\n",
    "                    if file_id in artifact_numbers:\n",
    "                        t_artifact.append(file_path)\n",
    "                    else:\n",
    "                        t_non_artifact.append(file_path)\n",
    "                os.chdir('..')\n",
    "        os.chdir(root)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import median\n",
    "\n",
    "# load all the text file data\n",
    "# we're loading both the f and t file data, \n",
    "# the first half of the matrix will be the \n",
    "# f data and the second half the t data\n",
    "data = []\n",
    "labels = []\n",
    "for f in f_artifact:\n",
    "    with open(f) as file: \n",
    "        temp = []\n",
    "        for line in file: \n",
    "            temp.append(float(line.strip()))\n",
    "        median = np.median(temp)\n",
    "        while len(temp) < 282: \n",
    "            temp.append(median)\n",
    "        data.append(temp)\n",
    "        labels.append(1)\n",
    "\n",
    "for f in f_non_artifact: \n",
    "    with open(f) as file: \n",
    "        temp = []\n",
    "        for line in file: \n",
    "            temp.append(float(line.strip()))\n",
    "        median = np.median(temp)\n",
    "        while len(temp) < 282: \n",
    "            temp.append(median)\n",
    "        data.append(temp)\n",
    "        labels.append(0)\n",
    "\n",
    "    \n",
    "for t in t_artifact: \n",
    "    with open(t) as file: \n",
    "        temp = []\n",
    "        for line in file: \n",
    "            temp.append(float(line.strip()))\n",
    "        median = np.median(temp)\n",
    "        while len(temp) < 282: \n",
    "            temp.append(median)\n",
    "        data.append(temp)\n",
    "        labels.append(1)\n",
    "\n",
    "\n",
    "for t in t_non_artifact: \n",
    "    with open(t) as file: \n",
    "        temp = []\n",
    "        for line in file: \n",
    "            temp.append(float(line.strip()))\n",
    "        median = np.median(temp)\n",
    "        while len(temp) < 282: \n",
    "            temp.append(median)\n",
    "        data.append(temp)\n",
    "        labels.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.array(data)\n",
    "# labels = np.array(labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2778.006017  ,   521.0505664 ,   708.3873767 , ...,\n",
       "          171.7263595 ,   171.7263595 ,   171.7263595 ],\n",
       "       [ 4436.754673  ,  1258.587893  ,   565.7003426 , ...,\n",
       "          207.9361344 ,   207.9361344 ,   207.9361344 ],\n",
       "       [ 6027.02926   ,  1214.354164  ,    50.05103923, ...,\n",
       "          135.54185855,   135.54185855,   135.54185855],\n",
       "       ...,\n",
       "       [   24.9023011 ,   113.4078749 ,    49.6962332 , ...,\n",
       "          169.94132255,   169.94132255,   169.94132255],\n",
       "       [ 2491.136012  ,   306.8752783 ,   181.917421  , ...,\n",
       "          167.28791695,   167.28791695,   167.28791695],\n",
       "       [17932.4755    ,   712.7611864 ,  1452.748157  , ...,\n",
       "           60.54242396,    60.54242396,    60.54242396]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imputer = Imputer(strategy=\"median\")\n",
    "\n",
    "imputer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6782178217821783"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)\n",
    "\n",
    "# svm_clf = SVC(kernel=\"poly\", degree=3, coef0=1, C=5)\n",
    "# svm_clf.fit(X_train, y_train)\n",
    "# y_pred = svm_clf.predict(X_test)\n",
    "# extra_trees_clf = ExtraTrees\n",
    "\n",
    "random_forest_clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "random_forest_clf.fit(X_train, y_train)\n",
    "y_pred = random_forest_clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "# score = cross_val_score(log_clf, X_train, y_train, cv=5, verbose=3)\n",
    "# score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mac2researchlab/Desktop/brandon_melodic/melodic-classifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "os.chdir(scriptDir)\n",
    "print(scriptDir)\n",
    "joblib.dump(random_forest_clf, \"random_forest_clf.pkl\")\n",
    "random_forest_clf_loaded = joblib.load(\"random_forest_clf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-f34e73a3b6b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m               \"criterion\": [\"gini\", \"entropy\"]}\n\u001b[1;32m     10\u001b[0m \u001b[0mrnd_search_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_forest_clf_loaded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;31m# Regenerate parameter iterable for each fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0mcandidate_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m         \u001b[0mn_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;31m# look up sampled parameter settings in parameter grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mgrid_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgrid_size\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mproduct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         return sum(product(len(v) for v in p.values()) if p else 1\n\u001b[0;32m--> 124\u001b[0;31m                    for p in self.param_grid)\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mproduct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         return sum(product(len(v) for v in p.values()) if p else 1\n\u001b[0;32m--> 124\u001b[0;31m                    for p in self.param_grid)\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# Product function that can handle iterables (np.product can't).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mproduct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         return sum(product(len(v) for v in p.values()) if p else 1\n\u001b[0m\u001b[1;32m    124\u001b[0m                    for p in self.param_grid)\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import reciprocal, uniform\n",
    "\n",
    "# param_distributions = {\"gamma\": reciprocal(0.001, 0.1), \"C\": uniform(1, 10)}\n",
    "# param_distributions = {\"n_estimators\": 15, \"random_state\": 42}\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "rnd_search_cv = RandomizedSearchCV(random_forest_clf_loaded, param_distributions=param_distributions, n_iter=10, verbose=2, cv=5)\n",
    "rnd_search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_estimator_.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rnd_search_cv.best_estimator_.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(precision_score(y_pred, y_test))\n",
    "print(recall_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
